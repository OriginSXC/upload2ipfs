name: IPFS Gateway Remote Probe (multi-region) + Patch index.html

on:
  workflow_dispatch:
    inputs:
      nodes:
        description: "Check-Host nodes per URL (3-7 recommended)"
        required: false
        default: "5"
      cid:
        description: "IPFS CID to test (only for probing; index.html 不改CID)"
        required: false
        default: "bafybeifx7yeb55armcsxwwitkymga5xf53dxiarykms3ygqic223w5sk3m"
  push:
    branches: [ "master", "main" ]
    paths:
      - 'index.html'
      - 'gateways.js'
      - 'gateways.txt'
      - '.github/workflows/ipfs-gateway-remote-probe.yml'
  schedule:
    - cron: "23 2 * * *"  # 每天 02:23 UTC 运行

permissions:
  contents: write

concurrency:
  group: ipfs-gateway-remote-probe
  cancel-in-progress: false

jobs:
  probe:
    runs-on: ubuntu-latest
    timeout-minutes: 120
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Set up Node
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install Python deps
        run: pip install requests

      - name: Write remote_probe_checkhost.py (DEFAULT_CID updated)
        shell: bash
        run: |
          python - <<'PY'
          import textwrap, pathlib
          code = r'''
          #!/usr/bin/env python3
          # -*- coding: utf-8 -*-
          import argparse, csv, re, time, requests
          CHECK_HTTP = "https://check-host.net/check-http"
          CHECK_RESULT = "https://check-host.net/check-result/{rid}"
          # 默认探测CID（可在 workflow_dispatch 输入覆盖）
          DEFAULT_CID = "bafybeifx7yeb55armcsxwwitkymga5xf53dxiarykms3ygqic223w5sk3m"

          def parse_urls(path: str):
              text = open(path, "r", encoding="utf-8", errors="ignore").read()
              urls = re.findall(r'https?://[^"\\s]+', text)
              clean, seen = [], set()
              for u in urls:
                  u = u.strip().rstrip(",")
                  if u and u not in seen and (u.startswith("http://") or u.startswith("https://")):
                      seen.add(u); clean.append(u)
              if not clean: raise RuntimeError("No http(s) URLs found in input file.")
              return clean

          def build_test_url(base: str, cid: str):
              return ("POST", f"{base}{cid}") if "/api/v0/cat" in base else ("GET", f"{base}{cid}")

          def start_check(url: str, max_nodes: int) -> dict:
              r = requests.get(CHECK_HTTP, params={"host": url, "max_nodes": max_nodes},
                               headers={"Accept": "application/json"}, timeout=15)
              r.raise_for_status()
              return r.json()

          def poll_result(request_id: str, timeout_s: float = 25.0, interval_s: float = 0.8) -> dict:
              t0 = time.time()
              while True:
                  r = requests.get(CHECK_RESULT.format(rid=request_id),
                                   headers={"Accept": "application/json"}, timeout=15)
                  r.raise_for_status()
                  data = r.json()
                  if data and all(v is not None for v in data.values()):
                      return data
                  if time.time() - t0 > timeout_s:
                      return data or {}
                  time.sleep(interval_s)

          def summarize(node_results: dict):
              total = ready = ok_nodes = 0
              codes, fastest = [], None
              for _, arr in node_results.items():
                  total += 1
                  if arr is None or not arr: continue
                  ready += 1
                  entry = arr[0]
                  try: success = int(entry[0])
                  except: success = 0
                  try: t = float(entry[1]) if entry[1] is not None else None
                  except: t = None
                  code = str(entry[3]) if len(entry) > 3 and entry[3] is not None else ""
                  if code: codes.append(code)
                  if code or success == 1:
                      ok_nodes += 1
                      if t is not None: fastest = t if fastest is None else min(fastest, t)
              return {
                  "nodes_total": total,
                  "nodes_ready": ready,
                  "nodes_ok": ok_nodes,
                  "codes": "|".join(sorted(set(codes))),
                  "fastest_s": "" if fastest is None else f"{fastest:.3f}",
                  "exists": 1 if ok_nodes > 0 else 0,
              }

          def main():
              ap = argparse.ArgumentParser()
              ap.add_argument("input")
              ap.add_argument("--cid", default=DEFAULT_CID)
              ap.add_argument("--nodes", type=int, default=5)
              ap.add_argument("--csv", default="reports/results_checkhost.csv")
              ap.add_argument("--sleep", type=float, default=0.6)
              args = ap.parse_args()

              urls = parse_urls(args.input)
              print(f"Found {len(urls)} URLs; probing with {args.nodes} nodes each...")
              with open(args.csv, "w", newline="", encoding="utf-8") as f:
                  w = csv.writer(f)
                  w.writerow(["base","method","test_url","exists","nodes_total","nodes_ready","nodes_ok","codes","fastest_s","permanent_link","request_id"])
                  for base in urls:
                      method, test_url = build_test_url(base, args.cid)
                      try:
                          kickoff = start_check(test_url, args.nodes)
                          rid = kickoff.get("request_id", ""); perm = kickoff.get("permanent_link", "")
                          node_results = poll_result(rid)
                          summary = summarize(node_results)
                          w.writerow([base, method, test_url, summary["exists"], summary["nodes_total"], summary["nodes_ready"], summary["nodes_ok"], summary["codes"], summary["fastest_s"], perm, rid])
                          print(f"[{ 'ONLINE' if summary['exists'] else 'OFFLINE' }] {base} ok={summary['nodes_ok']}/{summary['nodes_total']} codes={summary['codes']}")
                      except Exception as e:
                          w.writerow([base, method, test_url, 0, "", "", "", "", "", "", ""])
                          print(f"[ERROR] {base} -> {e}")
                      time.sleep(args.sleep)
              print(f"Done. CSV saved to: {args.csv}")

          if __name__ == "__main__":
              main()
          '''
          pathlib.Path("remote_probe_checkhost.py").write_text(textwrap.dedent(code), encoding="utf-8")
          pathlib.Path("remote_probe_checkhost.py").chmod(0o755)
          PY

      # === Build gateways.js (robust, no heredoc). Prefer existing valid sources; otherwise fallback ===
      - name: Build gateways.js from existing sources or embedded list (robust)
        shell: bash
        run: |
          set -euo pipefail
          cat > build-gateways.js <<'JAVASCRIPT'
          const fs = require('fs');
          const has = p => fs.existsSync(p);
          const read = p => fs.readFileSync(p,'utf8');

          function writeFromArray(arr, reason){
            const js = "const downloadGateways = [\n  " + arr.map(u=>JSON.stringify(u)).join(",\n  ") + "\n];\n";
            fs.writeFileSync('gateways.js', js);
            console.log('gateways.js written from', reason, `(count=${arr.length})`);
          }

          // 1) If gateways.js exists AND contains array, keep it as source-of-truth
          if (has('gateways.js')){
            const txt = read('gateways.js');
            if (/downloadGateways\s*=\s*\[[\s\S]*?\]/m.test(txt)){
              console.log('Existing gateways.js contains downloadGateways; keep as-is.');
              process.exit(0);
            } else {
              console.warn('gateways.js exists but no downloadGateways array; will try other sources.');
            }
          }

          // 2) If gateways.txt exists, build from it
          if (has('gateways.txt')){
            const arr = read('gateways.txt').split(/\r?\n/).map(s=>s.trim()).filter(Boolean);
            if (arr.length){ writeFromArray(arr, 'gateways.txt'); process.exit(0); }
          }

          // 3) Try parse index.html for an existing array
          if (has('index.html')){
            const html = read('index.html');
            const m = html.match(/downloadGateways\s*=\s*(\[[\s\S]*?\])\s*;?/m) ||
                      html.match(/(?:const|let|var)\s+downloadGateways\s*=\s*(\[[\s\S]*?\])\s*;?/m);
            if (m){
              try {
                // Try to eval the JSON-ish array to a JS array safely
                const arr = Function('return ' + m[1])();
                if (Array.isArray(arr) && arr.length){ writeFromArray(arr, 'index.html'); process.exit(0); }
              } catch (e) {
                console.warn('Failed to parse array from index.html, will fallback.');
              }
            }
          }

          // 4) Fallback minimal list
          writeFromArray([
            'https://ipfs.io/ipfs/',
            'https://cloudflare-ipfs.com/ipfs/',
            'https://w3s.link/ipfs/',
            'https://nftstorage.link/ipfs/'
          ], 'fallback');
          JAVASCRIPT
          
          node build-gateways.js

      # === Patch index.html: ONLY update downloadGateways; DO NOT change any CID ===
      - name: Patch index.html (downloadGateways only; robust)
        shell: bash
        run: |
          set -euo pipefail
          if [[ ! -f index.html ]]; then
            echo "index.html not found at repo root; skip patch."
            exit 0
          fi

          cat > patch-script.js <<'JAVASCRIPT'
          const fs = require('fs');
          const has = p => fs.existsSync(p);
          const read = p => fs.readFileSync(p,'utf8');

          function buildGwList(){
            if (has('gateways.js')){
              const txt = read('gateways.js');
              const m = txt.match(/downloadGateways\s*=\s*(\[[\s\S]*?\])\s*;?/m);
              if (m) return m[1];
            }
            if (has('gateways.txt')){
              const arr = read('gateways.txt').split(/\r?\n/).map(s=>s.trim()).filter(Boolean);
              if (arr.length) return "[\n  " + arr.map(u=>JSON.stringify(u)).join(",\n  ") + "\n]";
            }
            // hard fallback
            const arr = [
              'https://ipfs.io/ipfs/','https://cloudflare-ipfs.com/ipfs/','https://w3s.link/ipfs/','https://nftstorage.link/ipfs/'
            ];
            return "[\n  " + arr.map(u=>JSON.stringify(u)).join(",\n  ") + "\n]";
          }

          let html = read('index.html');
          const gwList = buildGwList();

          const patterns = [
            /\bdownloadGateways\s*=\s*\[[\s\S]*?\]\s*;?/m,
            /\b(?:const|let|var)\s+downloadGateways\s*=\s*\[[\s\S]*?\]\s*;?/m
          ];

          let replaced = false;
          for (const re of patterns){
            if (re.test(html)){
              html = html.replace(re, 'downloadGateways = ' + gwList + ';');
              replaced = true;
              break;
            }
          }

          if (!replaced){
            if (/<\/body>/i.test(html)){
              html = html.replace(/<\/body>/i, '<script>const downloadGateways = ' + gwList + ';<\/script>\\n</body>');
              replaced = true;
            } else if (/<\/head>/i.test(html)){
              html = html.replace(/<\/head>/i, '<script>const downloadGateways = ' + gwList + ';<\/script>\\n</head>');
              replaced = true;
            } else {
              // append at end
              html += '\\n<script>const downloadGateways = ' + gwList + ';<\/script>\\n';
              replaced = true;
            }
          }

          fs.writeFileSync('index.html', html);
          console.log(replaced ? 'downloadGateways written/replaced.' : 'WARN: still not written.');
          JAVASCRIPT
          
          node patch-script.js

      - name: Run probe (multi-region)
        id: runprobe
        shell: bash
        env:
          NODES: ${{ github.event.inputs.nodes }}
          CID: ${{ github.event.inputs.cid }}
        run: |
          set -euo pipefail
          LIST_FILE="gateways.js"
          # If gateways.txt exists, prefer it as the source, as it's simpler for users.
          [[ -f gateways.txt ]] && LIST_FILE="gateways.txt"

          mkdir -p reports
          EXTRA_ARGS=""
          # Only add --cid if the CID input is not empty
          if [[ -n "${CID:-}" ]]; then
            EXTRA_ARGS="--cid ${CID}"
          fi
          python remote_probe_checkhost.py "$LIST_FILE" --nodes "${NODES:-5}" --csv reports/results_checkhost.csv $EXTRA_ARGS

          TS=$(date -u +"%Y-%m-%dT%H-%M-%SZ")
          cp reports/results_checkhost.csv "reports/ipfs_gateways_${TS}.csv"
          cp reports/results_checkhost.csv "reports/latest_ipfs_gateways.csv"

      - name: Commit changes (CSV + patched index.html)
        shell: bash
        run: |
          set -e
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add reports/*.csv || true
          git add index.html || true
          git add gateways.js || true
          # Use a default value for the CID in the commit message if it's not provided
          COMMIT_CID="${{ github.event.inputs.cid }}"
          if [[ -z "$COMMIT_CID" ]]; then
            COMMIT_CID="default"
          fi
          git commit -m "Probe & patch: gateways list updated; probe CID=${COMMIT_CID} @ $(date -u +'%Y-%m-%dT%H:%M:%SZ')" || echo "Nothing to commit"
          git push

      - name: Upload artifact (CSV)
        uses: actions/upload-artifact@v4
        with:
          name: ipfs-gateway-probe-${{ github.run_id }}
          path: reports/*.csv
