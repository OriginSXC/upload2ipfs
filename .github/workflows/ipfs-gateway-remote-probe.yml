name: IPFS Gateway Remote Probe (multi-region) + Patch index.html

on:
  workflow_dispatch:
    inputs:
      nodes:
        description: "Check-Host nodes per URL (3-7 recommended)"
        required: false
        default: "5"
      cid:
        description: "IPFS CID to test (only for probing; index.html 不改CID)"
        required: false
        default: "bafybeifx7yeb55armcsxwwitkymga5xf53dxiarykms3ygqic223w5sk3m"
  push:
    branches: [ master, main ]  # 改成你的默认分支
    paths:
      - 'index.html'
      - 'gateways.js'
      - 'gateways.txt'
      - '.github/workflows/ipfs-gateway-remote-probe.yml'
  schedule:
    - cron: "23 2 * * *"   # 每天 02:23 UTC

permissions:
  contents: write

concurrency:
  group: ipfs-gateway-remote-probe
  cancel-in-progress: false

jobs:
  probe:
    runs-on: ubuntu-latest
    timeout-minutes: 120
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Set up Node
        uses: actions/setup-node@v4
        with:
          node-version: "20"

      - name: Install Python deps
        run: pip install requests

      # --- Ensure gateways.js exists (robust; no heredoc conflicts) ---
      - name: Ensure gateways.js (robust)
        shell: bash
        run: |
          set -euo pipefail
          if [[ -f gateways.js ]] && grep -qE 'downloadGateways\s*=\s*\[' gateways.js; then
            echo "Using existing gateways.js with downloadGateways array";
          elif [[ -f gateways.txt ]]; then
            node <<'NODE'
            const fs = require('fs');
            const arr = fs.readFileSync('gateways.txt','utf8').split(/\r?\n/).map(s=>s.trim()).filter(Boolean);
            const js = "const downloadGateways = [\n  " + arr.map(u=>JSON.stringify(u)).join(",\n  ") + "\n];\n";
            fs.writeFileSync('gateways.js', js);
            console.log('gateways.js built from gateways.txt');
            NODE
          elif [[ -f index.html ]]; then
            node <<'NODE'
            const fs = require('fs');
            const s = fs.readFileSync('index.html','utf8');
            const m = s.match(/\bdownloadGateways\s*=\s*(\[[\s\S]*?\])\s*;?/m);
            if (m) {
              fs.writeFileSync('gateways.js', "const downloadGateways = " + m[1] + "\n");
              console.log('gateways.js extracted from index.html');
            } else {
              const list = ["https://ipfs.io/ipfs/","https://cloudflare-ipfs.com/ipfs/","https://w3s.link/ipfs/","https://nftstorage.link/ipfs/"];
              const js = "const downloadGateways = [\n  " + list.map(u=>JSON.stringify(u)).join(",\n  ") + "\n];\n";
              fs.writeFileSync('gateways.js', js);
              console.log('gateways.js created with fallback list (no array in index.html)');
            }
            NODE
          else
            node <<'NODE'
            const fs = require('fs');
            const list = ["https://ipfs.io/ipfs/","https://cloudflare-ipfs.com/ipfs/","https://w3s.link/ipfs/","https://nftstorage.link/ipfs/"];
            const js = "const downloadGateways = [\n  " + list.map(u=>JSON.stringify(u)).join(",\n  ") + "\n];\n";
            fs.writeFileSync('gateways.js', js);
            console.log('gateways.js created with fallback list (no index.html)');
            NODE
          fi

      # --- Patch index.html: ONLY replace downloadGateways; do not touch CID ---
      - name: Patch index.html (downloadGateways only; robust)
        if: ${{ hashFiles('index.html') != '' }}
        shell: bash
        run: |
          set -euo pipefail
          node <<'NODE'
          const fs = require('fs');
          if (!fs.existsSync('index.html')) { process.exit(0); }
          let gwList = null;
          if (fs.existsSync('gateways.js')) {
            const t = fs.readFileSync('gateways.js','utf8');
            const m = t.match(/downloadGateways\s*=\s*(\[[\s\S]*?\])\s*;?/m);
            if (m) gwList = m[1];
          }
          if (!gwList && fs.existsSync('gateways.txt')) {
            const arr = fs.readFileSync('gateways.txt','utf8').split(/\r?\n/).map(s=>s.trim()).filter(Boolean);
            if (arr.length) gwList = "[\n  " + arr.map(u=>JSON.stringify(u)).join(",\n  ") + "\n]";
          }
          if (!gwList) {
            console.error('No gateways list available; will inject fallback');
            const list = ["https://ipfs.io/ipfs/","https://cloudflare-ipfs.com/ipfs/","https://w3s.link/ipfs/","https://nftstorage.link/ipfs/"];
            gwList = "[\n  " + list.map(u=>JSON.stringify(u)).join(",\n  ") + "\n]";
          }
          let html = fs.readFileSync('index.html','utf8');
          const patterns = [
            /\bdownloadGateways\s*=\s*\[[\s\S]*?\]\s*;?/m,
            /\b(?:const|let|var)\s+downloadGateways\s*=\s*\[[\s\S]*?\]\s*;?/m
          ];
          let replaced = false;
          for (const re of patterns) {
            if (re.test(html)) { html = html.replace(re, `downloadGateways = ${gwList};`); replaced = true; break; }
          }
          if (!replaced) {
            if (/<\/body>/i.test(html)) {
              html = html.replace(/<\/body>/i, `<script>const downloadGateways = ${gwList};<\/script>\n</body>`);
              replaced = true;
            } else if (/<\/head>/i.test(html)) {
              html = html.replace(/<\/head>/i, `<script>const downloadGateways = ${gwList};<\/script>\n</head>`);
              replaced = true;
            }
          }
          fs.writeFileSync('index.html', html);
          console.log(replaced ? 'downloadGateways written/replaced.' : 'WARN: still not written.');
          NODE

      # --- Create remote_probe_checkhost.py (heredoc; safe) ---
      - name: Create remote_probe_checkhost.py
        shell: bash
        run: |
          set -euo pipefail
          cat > remote_probe_checkhost.py <<'PY'
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import argparse, csv, re, time, requests

CHECK_HTTP = "https://check-host.net/check-http"
CHECK_RESULT = "https://check-host.net/check-result/{rid}"

def parse_urls(path: str):
    text = open(path, "r", encoding="utf-8", errors="ignore").read()
    urls = re.findall(r"https?://[^\"\s]+", text)
    clean, seen = [], set()
    for u in urls:
        u = u.strip().rstrip(",")
        if u and u not in seen and (u.startswith("http://") or u.startswith("https://")):
            seen.add(u); clean.append(u)
    if not clean: raise RuntimeError("No http(s) URLs found in input file.")
    return clean

def build_test_url(base: str, cid: str):
    return ("POST", f"{base}{cid}") if "/api/v0/cat" in base else ("GET", f"{base}{cid}")

def start_check(url: str, max_nodes: int) -> dict:
    r = requests.get(CHECK_HTTP, params={"host": url, "max_nodes": max_nodes},
                     headers={"Accept": "application/json"}, timeout=15)
    r.raise_for_status()
    return r.json()

def poll_result(request_id: str, timeout_s: float = 25.0, interval_s: float = 0.8) -> dict:
    t0 = time.time()
    while True:
        r = requests.get(CHECK_RESULT.format(rid=request_id),
                         headers={"Accept": "application/json"}, timeout=15)
        r.raise_for_status()
        data = r.json()
        if data and all(v is not None for v in data.values()):
            return data
        if time.time() - t0 > timeout_s:
            return data or {}
        time.sleep(interval_s)

def summarize(node_results: dict):
    total = ready = ok_nodes = 0
    codes, fastest = [], None
    for _, arr in node_results.items():
        total += 1
        if arr is None or not arr: continue
        ready += 1
        entry = arr[0]
        try: success = int(entry[0])
        except: success = 0
        try: t = float(entry[1]) if entry[1] is not None else None
        except: t = None
        code = str(entry[3]) if len(entry) > 3 and entry[3] is not None else ""
        if code: codes.append(code)
        if code or success == 1:
            ok_nodes += 1
            if t is not None: fastest = t if fastest is None else min(fastest, t)
    return {
        "nodes_total": total,
        "nodes_ready": ready,
        "nodes_ok": ok_nodes,
        "codes": "|".join(sorted(set(codes))),
        "fastest_s": "" if fastest is None else f"{fastest:.3f}",
        "exists": 1 if ok_nodes > 0 else 0,
    }

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("input")
    ap.add_argument("--cid", default="bafybeifx7yeb55armcsxwwitkymga5xf53dxiarykms3ygqic223w5sk3m")
    ap.add_argument("--nodes", type=int, default=5)
    ap.add_argument("--csv", default="reports/results_checkhost.csv")
    ap.add_argument("--sleep", type=float, default=0.6)
    args = ap.parse_args()

    urls = parse_urls(args.input)
    print(f"Found {len(urls)} URLs; probing with {args.nodes} nodes each...")
    with open(args.csv, "w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        w.writerow(["base","method","test_url","exists","nodes_total","nodes_ready","nodes_ok","codes","fastest_s","permanent_link","request_id"])
        for base in urls:
            method, test_url = build_test_url(base, args.cid)
            try:
                kickoff = start_check(test_url, args.nodes)
                rid = kickoff.get("request_id", ""); perm = kickoff.get("permanent_link", "")
                node_results = poll_result(rid)
                summary = summarize(node_results)
                w.writerow([base, method, test_url, summary["exists"], summary["nodes_total"], summary["nodes_ready"], summary["nodes_ok"], summary["codes"], summary["fastest_s"], perm, rid])
                print(f"[{ 'ONLINE' if summary['exists'] else 'OFFLINE' }] {base} ok={summary['nodes_ok']}/{summary['nodes_total']} codes={summary['codes']}")
            except Exception as e:
                w.writerow([base, method, test_url, 0, "", "", "", "", "", "", ""]) 
                print(f"[ERROR] {base} -> {e}")
            time.sleep(args.sleep)
    print(f"Done. CSV saved to: {args.csv}")

if __name__ == "__main__":
    main()
PY
          chmod +x remote_probe_checkhost.py

      # --- Run probe (multi-region) ---
      - name: Run probe (multi-region)
        env:
          NODES: ${{ github.event.inputs.nodes }}
          CID: ${{ github.event.inputs.cid }}
        run: |
          set -euo pipefail
          LIST_FILE="gateways.js"
          [[ -f gateways.txt ]] && LIST_FILE="gateways.txt"

          mkdir -p reports
          EXTRA=""
          if [[ -n "${CID:-}" ]]; then EXTRA="--cid ${CID}"; fi

          python3 remote_probe_checkhost.py "$LIST_FILE" --nodes "${NODES:-5}" --csv reports/results_checkhost.csv $EXTRA

          TS=$(date -u +"%Y-%m-%dT%H-%M-%SZ")
          cp reports/results_checkhost.csv "reports/ipfs_gateways_${TS}.csv"
          cp reports/results_checkhost.csv "reports/latest_ipfs_gateways.csv"

      - name: Commit changes (CSV + patched index.html)
        shell: bash
        run: |
          set -e
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add reports/*.csv || true
          git add index.html || true
          git add gateways.js || true
          git commit -m "Probe & patch: gateways list updated; probe CID=${{ github.event.inputs.cid }} @ $(date -u +'%Y-%m-%dT%H:%M:%SZ')" || echo "Nothing to commit"
          git push

      - name: Upload artifact (CSV)
        uses: actions/upload-artifact@v4
        with:
          name: ipfs-gateway-probe-${{ github.run_id }}
          path: reports/*.csv
